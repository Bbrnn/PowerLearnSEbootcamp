{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c326ce3",
   "metadata": {},
   "source": [
    "# COVID-19 Global Data\n",
    "\n",
    "The COVID-19 Global Data Tracker is a powerful real-world project that builds strong skills in data cleaning, EDA, and data visualization. Let's do it step by step, and Iâ€™ll walk you through everything."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77ff39c",
   "metadata": {},
   "source": [
    "Step1: data loading and exloration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e99072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Dataset preview\n",
      "  iso_code continent     location        date  total_cases  new_cases  \\\n",
      "0      AFG      Asia  Afghanistan  2020-01-05          0.0        0.0   \n",
      "1      AFG      Asia  Afghanistan  2020-01-06          0.0        0.0   \n",
      "2      AFG      Asia  Afghanistan  2020-01-07          0.0        0.0   \n",
      "3      AFG      Asia  Afghanistan  2020-01-08          0.0        0.0   \n",
      "4      AFG      Asia  Afghanistan  2020-01-09          0.0        0.0   \n",
      "\n",
      "   new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  ...  \\\n",
      "0                 NaN           0.0         0.0                  NaN  ...   \n",
      "1                 NaN           0.0         0.0                  NaN  ...   \n",
      "2                 NaN           0.0         0.0                  NaN  ...   \n",
      "3                 NaN           0.0         0.0                  NaN  ...   \n",
      "4                 NaN           0.0         0.0                  NaN  ...   \n",
      "\n",
      "   male_smokers  handwashing_facilities  hospital_beds_per_thousand  \\\n",
      "0           NaN                  37.746                         0.5   \n",
      "1           NaN                  37.746                         0.5   \n",
      "2           NaN                  37.746                         0.5   \n",
      "3           NaN                  37.746                         0.5   \n",
      "4           NaN                  37.746                         0.5   \n",
      "\n",
      "   life_expectancy  human_development_index  population  \\\n",
      "0            64.83                    0.511    41128772   \n",
      "1            64.83                    0.511    41128772   \n",
      "2            64.83                    0.511    41128772   \n",
      "3            64.83                    0.511    41128772   \n",
      "4            64.83                    0.511    41128772   \n",
      "\n",
      "   excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
      "0                                   NaN                          NaN   \n",
      "1                                   NaN                          NaN   \n",
      "2                                   NaN                          NaN   \n",
      "3                                   NaN                          NaN   \n",
      "4                                   NaN                          NaN   \n",
      "\n",
      "   excess_mortality  excess_mortality_cumulative_per_million  \n",
      "0               NaN                                      NaN  \n",
      "1               NaN                                      NaN  \n",
      "2               NaN                                      NaN  \n",
      "3               NaN                                      NaN  \n",
      "4               NaN                                      NaN  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1Load Data\n",
    "try:\n",
    "    df = pd.read_csv('owid-covid-data.csv')\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: owid-covid-data.csv not found. Please download and place it in your working directory.\")\n",
    "    raise\n",
    "\n",
    "#preview the dataset\n",
    "print(\"Dataset preview\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5dda7604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column names:\n",
      "Index(['iso_code', 'continent', 'location', 'date', 'total_cases', 'new_cases',\n",
      "       'new_cases_smoothed', 'total_deaths', 'new_deaths',\n",
      "       'new_deaths_smoothed', 'total_cases_per_million',\n",
      "       'new_cases_per_million', 'new_cases_smoothed_per_million',\n",
      "       'total_deaths_per_million', 'new_deaths_per_million',\n",
      "       'new_deaths_smoothed_per_million', 'reproduction_rate', 'icu_patients',\n",
      "       'icu_patients_per_million', 'hosp_patients',\n",
      "       'hosp_patients_per_million', 'weekly_icu_admissions',\n",
      "       'weekly_icu_admissions_per_million', 'weekly_hosp_admissions',\n",
      "       'weekly_hosp_admissions_per_million', 'total_tests', 'new_tests',\n",
      "       'total_tests_per_thousand', 'new_tests_per_thousand',\n",
      "       'new_tests_smoothed', 'new_tests_smoothed_per_thousand',\n",
      "       'positive_rate', 'tests_per_case', 'tests_units', 'total_vaccinations',\n",
      "       'people_vaccinated', 'people_fully_vaccinated', 'total_boosters',\n",
      "       'new_vaccinations', 'new_vaccinations_smoothed',\n",
      "       'total_vaccinations_per_hundred', 'people_vaccinated_per_hundred',\n",
      "       'people_fully_vaccinated_per_hundred', 'total_boosters_per_hundred',\n",
      "       'new_vaccinations_smoothed_per_million',\n",
      "       'new_people_vaccinated_smoothed',\n",
      "       'new_people_vaccinated_smoothed_per_hundred', 'stringency_index',\n",
      "       'population_density', 'median_age', 'aged_65_older', 'aged_70_older',\n",
      "       'gdp_per_capita', 'extreme_poverty', 'cardiovasc_death_rate',\n",
      "       'diabetes_prevalence', 'female_smokers', 'male_smokers',\n",
      "       'handwashing_facilities', 'hospital_beds_per_thousand',\n",
      "       'life_expectancy', 'human_development_index', 'population',\n",
      "       'excess_mortality_cumulative_absolute', 'excess_mortality_cumulative',\n",
      "       'excess_mortality', 'excess_mortality_cumulative_per_million'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Step 2.3: Check column names\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14550aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429435, 67)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20c46d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types\n",
      "iso_code                                    object\n",
      "continent                                   object\n",
      "location                                    object\n",
      "date                                        object\n",
      "total_cases                                float64\n",
      "                                            ...   \n",
      "population                                   int64\n",
      "excess_mortality_cumulative_absolute       float64\n",
      "excess_mortality_cumulative                float64\n",
      "excess_mortality                           float64\n",
      "excess_mortality_cumulative_per_million    float64\n",
      "Length: 67, dtype: object\n",
      "\n",
      "Missing values per column\n",
      "weekly_icu_admissions                   418442\n",
      "weekly_icu_admissions_per_million       418442\n",
      "excess_mortality                        416024\n",
      "excess_mortality_cumulative_absolute    416024\n",
      "excess_mortality_cumulative             416024\n",
      "                                         ...  \n",
      "total_cases_per_million                  17631\n",
      "location                                     0\n",
      "iso_code                                     0\n",
      "date                                         0\n",
      "population                                   0\n",
      "Length: 67, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData types\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nMissing values per column\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e9cca9",
   "metadata": {},
   "source": [
    "# Step 3: Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f14eccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "583d3c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing 'location' or 'date' (critical for analysis)\n",
    "df.dropna(subset=['location', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec7924a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fill missing numeric columns with forward fill (grouped by location)\n",
    "import numpy as np\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "df[num_cols] = df.groupby('location')[num_cols].apply(lambda group: group.ffill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fab1d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After cleaning, missing values in key columns:\n",
      "total_cases                0\n",
      "total_deaths               0\n",
      "total_vaccinations    338262\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop any remaining rows with critical missing data for total_cases and total_deaths\n",
    "df = df.dropna(subset=['total_cases', 'total_deaths'])\n",
    "\n",
    "print(\"\\nAfter cleaning, missing values in key columns:\")\n",
    "print(df[['total_cases', 'total_deaths', 'total_vaccinations']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "091539ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_cases            17631\n",
       "total_deaths           17631\n",
       "total_vaccinations    344018\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values in ey columns\n",
    "\n",
    "df[['total_cases', 'total_deaths', 'total_vaccinations']].isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12223449",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['total_cases', 'total_deaths', 'total_vaccinations']] = df[['total_cases', 'total_deaths', 'total_vaccinations']].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "239a1e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_cases           0\n",
       "total_deaths          0\n",
       "total_vaccinations    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['total_cases', 'total_deaths', 'total_vaccinations']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5941bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove aggregate regions\n",
    "aggregates = ['World', 'Africa', 'Asia', 'Europe', 'European Union',\n",
    "              'International', 'North America', 'Oceania', 'South America']\n",
    "\n",
    "df = df[~df['location'].isin(aggregates)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd0702de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['location', 'date']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9f228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
